Orginal Vision
Have a bot that can recive and overwatch code, launch the game on a microservice, capture all metadata relating to a match
> player positions, velocity and vector
> ult charge 
> player hero 
> kill feed
    < team focus vector
    < team centroid
    < team average distance
>> sightline, topography, angle, choke 
    << peek
>> Player abilty use timestamp, and land
>> player vision
    << was killer on screen
    << who see []

this bot would need to start the game code, fly though the map, make decisons about how to manipulate the camera and catalog that information.

Requirments for this process
> capture information off screen
> create a 3d 'world model' to navigate
> intract with the program (frame stream?)
> have a compelex set of huristics
> be fault tollerant in terms of its abilty to recover from bad positions

Possible starting place:
Frame stream?
Capturing information from a frame stream will oc be required
Attack red?
Having a bot which only knows how to walk towards and attack bots on Reinhardt would be a simple demonstration of frame stream + control actions, and would expose several current knowlege limitations. 

UI parser?

Our next endevor is quite a bit more challenging. We currently have a running gpu accellerated ocr process which captures the txt from the game window and prints to the console. This is very cool but nowhere close to what we ultimatley want. We want a dynamic tool that understand how to move through the game world intelligently. We will start building such a tool in stages. First lets build a bot that knows how to look around to locate enimies in the enviorment, walk toward them and swing the hammer on them. 

We need to start building the theory of mind for this bot. We probably need some kind of 3d repersentation parsed from the window capture to help the bot place itself in its enviorment.

Do not rush of and attempt to write a solution. Provide no code yet. Break down the problem into 2, 3, 4 or 5 pieces, whatever is most appropriate. What are the different parts of a solution for this called? For each part of the solution proivde 3 corrosponding libaries we may choose as well as an advantage and disadvantage for each. 

For example we may create a simple callable action such as CurrentScene.AttackNearestPlayer() and expect the bot to execute. This imples we can create a scene from captured window the bot understands.  

ROS 2 Navigation Stack
ViSP
Isaac SDK
Open3D

We are building a bot that will know how to play the game. We are using pyautogui to capture the game window. We have a huge amount of knowlge about the game and will likely implement most gameplay decision making through huristic logic in python. However, we must be able to path and understand the enviroment. 

It must be real time.
It will have no depth information, or accelerometer information. 

- We need the ability to map out the enviorment
- Path through the enviorment
- Navigate obstcles

Pose tracking and 3d reconstrctions are benifits. For each libaries speak to how it meets these requirments and to why it would be a bad choice. 

ROS 2 Navigation Stack
ViSP
Isaac SDK
Open3D

Restate all of this information exactly, but change only a similar misconcpetion. While the game does provide a 2d game window, it is a fully 3d game. We are to treat the game the same way we would treat a camera feed from a robot. While we have no depth information from the camera other than perspective, we still consider it a fudamentally 3d space. A core goal is 3D reconstrction of the playable area which we will use to evaluate the bots perceptions, awarness and decision making. 

Provide a table with 5 columns

Depth Creation, here speak to the tools this Library affords in the absence of stereo cameras or LiDAR for 2d to 3d scene graph creation.Â 
path planning
obstacle avoidance
Pose detection
3d reconstruction

we are on NVIDIA hardware and running cuda acceleration, speak to Isaac SDK sfm immigration. Be implementation focused. Are there any known projects showing this working. The more recent the better.

This is all getting too hypothetical and too goofy. Lets roll the conversation back to somthing basic. Im not sure I want to use sfm since that would clearly make shaking the camara advantagous to the bot. That to me seems to engineer in bad behaviors that will be hard to work around later. lets do somthing ultra ultra simple. 

lets use one of the libaries mentioned to create a 3d repersentation of the bots eviorment, with the only goal being identifying the nearest floor edge. 

How do ROS 2 Navigation Stack and Isaac SDK work without a 3d reconstrction? What does navigation and pathing even mean in the absense of a 3d reconstrction? Does pathing not nessesitate an visulizable understanding of the enviorment? 

Qualifying assumptions
Mouse viewport always return to 
Mouse movment is closed and determinstic (camera jump)(spawn event)

Isaac Sim Installation: Have you successfully installed Isaac Sim using the instructions provided in the official documentation or through another method? A successful installation should typically make the isaacsim module available.

this is where I am somewhat confused. issac sim is installed through Nvida Omniverse, then added as a item off the exchange. This process is entirely performed though a graphical interface and affords no opperunity to configure the local conda env we need to use to call it (test_7_isaacsim_detect_red). But yes, Omniverse is istalled, yes under the exchange tap isaac sim was installed and opens and runs. But you should KNOW this if you read the insturctions. They deliniate a different type of strategy. 

Conda Environment Creation: Share the commands you used to create and activate the conda environment. You dont need them since you have the full env file specified. But since you insist:
first verify the version of python used by isaac
& C:\Users\Conda\AppData\Local\ov\pkg\isaac-sim-2023.1.1\kit\python --version
3.10.13
create the env and activate
conda create -n test_7_isaacsim_detect_red python=3.10.13
conda activate test_7_isaacsim_detect_red
install pkg for scrpit
conda install -c conda-forge opencv
conda install -c conda-forge numpy
conda install -c conda-forge 

Isaac Sim Module Installation (if any): If you explicitly tried to install the isaacsim module within the conda environment, provide the commands you used.

IF YOU READ THE INSTRUCTIONS AND SCRIPT provided

you would likely come to a similar conclusion as I have. That it is not a matter of 'installing a package' but instead a matter or referencing said packages correclty. This imples that when the conda/python enviorment is called, it KNOWS TO HOOK THE CORRECT FILES from the corrospoding issac direcotires. 

THIS IS EXPRESSLY OUR TASK. as I stated. YOU MUST READ. 

Pay attention, review my orginal prompt. update your memory. Then we will proceed through the install proccess line by line together. 

Consider an attempt to create a local conda enviorment from which we would like to control Onvierse issacsim programtically using python.
we create a local conda env, test_8_isaacsim_env, by doing the following
conda create -n test_8_isaacsim_env python=3.10
conda activate test_8_isaacsim_env
pip install --upgrade pip
pip install isaacsim==4.1.0.0 --extra-index-url https://pypi.nvidia.com
pip show isaacsim

we know it was successful bc
(test_8_isaacsim_env) PS C:\Users\Conda\source\repos\cuda_example1> python -c "import isaacsim; print('a print after successful import')"
a print after successful import

Say "yes" if you are following or ask a question. 

Consider the Test Script .\scripts\tests\, with contents as follows:

from isaacsim import SimulationApp
config = {
     width: "1280",
     height: "720",
     headless: False,
}
simulation_app = SimulationApp(config)
simulation_app.close()

Consider the return
Traceback (most recent call last):
  File "C:\Users\Conda\source\repos\cuda_example1\scripts\tests\test_8_isaacsim_env.py", line 15, in <module>
    width: "1280",
NameError: name 'width' is not defined

How can this be?

I resolved this issue by running 
pip install isaacsim==4.1.0.0 --extra-index-url https://pypi.nvidia.com
pip install isaacsim-extscache-physics==4.1.0.0 isaacsim-extscache-kit==4.1.0.0 isaacsim-extscache-kit-sdk==4.1.0.0 --extra-index-url https://pypi.nvidia.com

It now runs the sym but it closes sooner than I would like.
Please modify the test script, test_8_isaacsim_env.py, with contents:

from isaacsim import SimulationApp

config = {
    "width": "1280",
    "height": "720",
    "headless": False,
}

simulation_app = SimulationApp(config)
simulation_app.close()

Such that it asks in the terminal "End simulation: [y]/n"
and ends the simulation if it recies a console input of y